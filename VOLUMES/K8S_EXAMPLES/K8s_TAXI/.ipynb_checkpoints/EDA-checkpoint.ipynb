{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/venv/lib/python3.7/site-packages (4.14.2)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/venv/lib/python3.7/site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/venv/lib/python3.7/site-packages (from plotly) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in /opt/venv/lib/python3.7/site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.7/site-packages (from missingno) (1.19.4)\n",
      "Requirement already satisfied: seaborn in /opt/venv/lib/python3.7/site-packages (from missingno) (0.11.1)\n",
      "Requirement already satisfied: matplotlib in /opt/venv/lib/python3.7/site-packages (from missingno) (3.3.3)\n",
      "Requirement already satisfied: scipy in /opt/venv/lib/python3.7/site-packages (from missingno) (1.5.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/venv/lib/python3.7/site-packages (from seaborn->missingno) (1.1.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/venv/lib/python3.7/site-packages (from matplotlib->missingno) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/venv/lib/python3.7/site-packages (from matplotlib->missingno) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/venv/lib/python3.7/site-packages (from matplotlib->missingno) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/venv/lib/python3.7/site-packages (from matplotlib->missingno) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/venv/lib/python3.7/site-packages (from matplotlib->missingno) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/venv/lib/python3.7/site-packages (from pandas>=0.23->seaborn->missingno) (2020.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib->missingno) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"k8s://https://kubernetes.default.svc.cluster.local:443\")\n",
    "sparkConf.setAppName(\"spark\")\n",
    "\n",
    "sparkConf.set(\"spark.kubernetes.container.image\", \"docker.io/iscp/pyspark-executor:latest\")\n",
    "sparkConf.set(\"spark.driver.host\", \"sn-deployment.spark.svc.cluster.local\")\n",
    "\n",
    "sparkConf.set(\"spark.executor.instances\", \"4\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"1g\")\n",
    "sparkConf.set(\"spark.executor.memory\", \"1g\")\n",
    "\n",
    "sparkConf.set(\"spark.kubernetes.namespace\", \"spark\")\n",
    "sparkConf.set(\"spark.kubernetes.driver.volumes.persistentVolumeClaim.snpvc.mount.path\", \"/home/volumes\")\n",
    "sparkConf.set(\"spark.kubernetes.driver.volumes.persistentVolumeClaim.snpvc.options.claimName\", \"snpvc\")\n",
    "sparkConf.set(\"spark.kubernetes.executor.volumes.persistentVolumeClaim.snpvc.mount.path\", \"/home/volumes\")\n",
    "sparkConf.set(\"spark.kubernetes.executor.volumes.persistentVolumeClaim.snpvc.options.claimName\", \"snpvc\")\n",
    "\n",
    "sparkConf.set('spark.sql.adaptive.enabled','True')\n",
    "sparkConf.set('spark.kubernetes.driver.pod.name','sn-deployment-0')\n",
    "# sparkConf.set('spark.dynamicAllocation.enabled', 'True')\n",
    "# sparkConf.set('spark.dynamicAllocation.shuffleTracking.enabled', 'True')\n",
    "# sparkConf.set('spark.dynamicAllocation.executorIdleTimeout', '2min')\n",
    "# sparkConf.set('spark.dynamicAllocation.minExecutors', '1')\n",
    "# sparkConf.set('spark.dynamicAllocation.maxExecutors', '1')\n",
    "# sparkConf.set('spark.dynamicAllocation.schedulerBacklogTimeout', '1m')\n",
    "# sparkConf.set('spark.shuffle.service.enabled', 'True')\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age\n",
    "sex: sex (1 = male; 0 = female)\n",
    "cp: chest pain type\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic\n",
    "trestbps: resting blood pressure (in mm Hg on admission to the \n",
    "        hospital)\n",
    "12 chol: serum cholestoral in mg/dl\n",
    "16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "19 restecg: resting electrocardiographic results\n",
    "        -- Value 0: normal\n",
    "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n",
    "                    elevation or depression of > 0.05 mV)\n",
    "        -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "                    by Estes' criteria\n",
    "32 thalach: maximum heart rate achieved\n",
    "38 exang: exercise induced angina (1 = yes; 0 = no)\n",
    "     40 oldpeak = ST depression induced by exercise relative to rest\n",
    "41 slope: the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping\n",
    "\n",
    " 44 ca: number of major vessels (0-3) colored by flourosopy\n",
    "\n",
    " 51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    " 58 num: diagnosis of heart disease (angiographic disease status)\n",
    "    -- Value 0: < 50% diameter narrowing\n",
    "    -- Value 1: > 50% diameter narrowing\n",
    "    (in any major vessel: attributes 59 through 68 are vessels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id,vendor_id,pickup_datetime,dropoff_datetime,passenger_count,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,store_and_fwd_flag,trip_duration\n",
    "# id2875421,2,2016-03-14 17:24:55,2016-03-14 17:32:30,1,-73.982154846191406,40.767936706542969,-73.964630126953125,40.765602111816406,N,455\n",
    "# id2377394,1,2016-06-12 00:43:35,2016-06-12 00:54:38,1,-73.980415344238281,40.738563537597656,-73.999481201171875,40.731151580810547,N,663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"\"\"id\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('train.csv', schema=schema, header=True, samplingRatio=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+\n",
      "|       id|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|  pickup_longitude|   pickup_latitude| dropoff_longitude|  dropoff_latitude|store_and_fwd_flag|trip_duration|\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+\n",
      "|id2875421|        2|2016-03-14 17:24:55|2016-03-14 17:32:30|              1| -73.9821548461914| 40.76793670654297|-73.96463012695312|40.765602111816406|                 N|          455|\n",
      "|id2377394|        1|2016-06-12 00:43:35|2016-06-12 00:54:38|              1|-73.98041534423828|40.738563537597656|-73.99948120117188| 40.73115158081055|                 N|          663|\n",
      "|id3858529|        2|2016-01-19 11:35:24|2016-01-19 12:10:48|              1| -73.9790267944336|40.763938903808594|-74.00533294677734|40.710086822509766|                 N|         2124|\n",
      "|id3504673|        2|2016-04-06 19:32:31|2016-04-06 19:39:40|              1|-74.01004028320312|   40.719970703125|-74.01226806640625| 40.70671844482422|                 N|          429|\n",
      "|id2181028|        2|2016-03-26 13:30:55|2016-03-26 13:38:10|              1|-73.97305297851562|40.793209075927734| -73.9729232788086| 40.78252029418945|                 N|          435|\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='id2875421', vendor_id=2, pickup_datetime='2016-03-14 17:24:55', dropoff_datetime='2016-03-14 17:32:30', passenger_count=1, pickup_longitude=-73.9821548461914, pickup_latitude=40.76793670654297, dropoff_longitude=-73.96463012695312, dropoff_latitude=40.765602111816406, store_and_fwd_flag='N', trip_duration=455),\n",
       " Row(id='id2377394', vendor_id=1, pickup_datetime='2016-06-12 00:43:35', dropoff_datetime='2016-06-12 00:54:38', passenger_count=1, pickup_longitude=-73.98041534423828, pickup_latitude=40.738563537597656, dropoff_longitude=-73.99948120117188, dropoff_latitude=40.73115158081055, store_and_fwd_flag='N', trip_duration=663)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- vendor_id: integer (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- trip_duration: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458644, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(),len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+-----------------+\n",
      "|summary|       id|          vendor_id|    pickup_datetime|   dropoff_datetime|   passenger_count|   pickup_longitude|    pickup_latitude|  dropoff_longitude|   dropoff_latitude|store_and_fwd_flag|    trip_duration|\n",
      "+-------+---------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+-----------------+\n",
      "|  count|  1458644|            1458644|            1458644|            1458644|           1458644|            1458644|            1458644|            1458644|            1458644|           1458644|          1458644|\n",
      "|   mean|     null| 1.5349502688798637|               null|               null|1.6645295219395548| -73.97348630489282| 40.750920908391734|  -73.9734159469458|   40.7517995149002|              null|959.4922729603659|\n",
      "| stddev|     null|0.49877715390740646|               null|               null|1.3142421678231109| 0.0709018584227027|0.03288118625763319| 0.0706432680971978|0.03589055560563539|              null|5237.431724497547|\n",
      "|    min|id0000001|                  1|2016-01-01 00:00:17|2016-01-01 00:03:31|                 0|-121.93334197998047|  34.35969543457031|-121.93330383300781|   32.1811408996582|                 N|                1|\n",
      "|    25%|     null|                  1|               null|               null|                 1| -73.99186706542969|  40.73735046386719| -73.99132537841797|  40.73588943481445|              null|              397|\n",
      "|    50%|     null|                  2|               null|               null|                 1| -73.98173522949219|  40.75409698486328| -73.97975158691406|  40.75452423095703|              null|              662|\n",
      "|    75%|     null|                  2|               null|               null|                 2| -73.96733093261719|  40.76835632324219| -73.96302032470703| 40.769805908203125|              null|             1075|\n",
      "|    max|id4000000|                  2|2016-06-30 23:59:39|2016-07-01 23:02:03|                 9| -61.33552932739258|  51.88108444213867| -61.33552932739258|  43.92102813720703|                 Y|          3526282|\n",
      "+-------+---------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = df.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Summary of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------------------+-------------------+-------------------+------------------+-------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|       id|          vendor_id|    pickup_datetime|   dropoff_datetime|   passenger_count|   pickup_longitude|     pickup_latitude|  dropoff_longitude|   dropoff_latitude|store_and_fwd_flag|     trip_duration|\n",
      "+-------+---------+-------------------+-------------------+-------------------+------------------+-------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|  1458644|            1458644|            1458644|            1458644|           1458644|            1458644|             1458644|            1458644|            1458644|           1458644|           1458644|\n",
      "|   mean|     null| 1.5349502688798637|               null|               null|1.6645295219395548| -73.97348630489282|  40.750920908391734|  -73.9734159469458|   40.7517995149002|              null| 959.4922729603659|\n",
      "| stddev|     null|0.49877715390739535|               null|               null|1.3142421678231355| 0.0709018584227041|0.032881186257630396|0.07064326809720285|0.03589055560563711|              null|5237.4317244975655|\n",
      "|    min|id0000001|                  1|2016-01-01 00:00:17|2016-01-01 00:03:31|                 0|-121.93334197998047|   34.35969543457031|-121.93330383300781|   32.1811408996582|                 N|                 1|\n",
      "|    25%|     null|                  1|               null|               null|                 1| -73.99186706542969|   40.73734664916992| -73.99132537841797| 40.735877990722656|              null|               397|\n",
      "|    50%|     null|                  2|               null|               null|                 1| -73.98173522949219|   40.75409698486328| -73.97975158691406|  40.75452423095703|              null|               662|\n",
      "|    75%|     null|                  2|               null|               null|                 2| -73.96732330322266|   40.76835632324219|  -73.9630126953125|  40.76980972290039|              null|              1075|\n",
      "|    max|id4000000|                  2|2016-06-30 23:59:39|2016-07-01 23:02:03|                 9| -61.33552932739258|   51.88108444213867| -61.33552932739258|  43.92102813720703|                 Y|           3526282|\n",
      "+-------+---------+-------------------+-------------------+-------------------+------------------+-------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_d.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('vendor_id', 'int'),\n",
       " ('pickup_datetime', 'string'),\n",
       " ('dropoff_datetime', 'string'),\n",
       " ('passenger_count', 'int'),\n",
       " ('pickup_longitude', 'double'),\n",
       " ('pickup_latitude', 'double'),\n",
       " ('dropoff_longitude', 'double'),\n",
       " ('dropoff_latitude', 'double'),\n",
       " ('store_and_fwd_flag', 'string'),\n",
       " ('trip_duration', 'int')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many unique values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    1458644\n",
       "vendor_id                   2\n",
       "pickup_datetime       1380222\n",
       "dropoff_datetime      1380377\n",
       "passenger_count            10\n",
       "pickup_longitude        23047\n",
       "pickup_latitude         45245\n",
       "dropoff_longitude       33821\n",
       "dropoff_latitude        62519\n",
       "store_and_fwd_flag          2\n",
       "trip_duration            7417\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_nunique = [f.countDistinct(c) for c in df_d.columns]\n",
    "df_d.select(list_of_nunique).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate columns that have bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d.select('ca').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d.groupBy('ca').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d.where(f.col('ca') == '?').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = df_d.replace(\"?\", None, subset = \"ca\")\n",
    "df_d.groupby('ca').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = df_d.replace(\"?\",None,subset=\"thal\")\n",
    "df_d.groupby(\"thal\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Null counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col = [f.count(f.when(f.col(c).isNull(),c)).alias(c) for c in df_d.columns]\n",
    "\n",
    "df_d.select(list_col).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_cnt(c):\n",
    "    return f.count(f.when(f.col(c).isNull(),c)).alias(c)\n",
    "\n",
    "map_of_nulls = map(get_null_cnt, df_d.columns )\n",
    "list_null_cnt = list(map_of_nulls)\n",
    "\n",
    "df_d.select(list_null_cnt).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get condition counts for all columns: check 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_cnt(c):\n",
    "    return f.count(f.when(f.col(c) == '0',c)).alias(c)\n",
    "\n",
    "map_of_nulls = map(get_null_cnt, df_d.columns )\n",
    "list_null_cnt = list(map_of_nulls)\n",
    "\n",
    "df_d.select(list_null_cnt).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill nulls with Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = df_d.withColumn('ca', f.col('ca').cast(types.IntegerType()))\n",
    "\n",
    "ca_median = df_d.approxQuantile(\"ca\", [0.5], 0.25)\n",
    "\n",
    "df_d = df_d.na.fill(ca_median[0])\n",
    "\n",
    "########################################\n",
    "\n",
    "df_d = df_d.withColumn('thal', f.col('thal').cast(types.IntegerType()))\n",
    "\n",
    "thal_median = df_d.approxQuantile(\"thal\", [0.5], 0.25)\n",
    "\n",
    "df_d = df_d.na.fill(thal_median[0])\n",
    "\n",
    "########################################\n",
    "\n",
    "list_col = [f.count(f.when(f.col(c).isNull(),c)).alias(c) for c in df_d.columns]\n",
    "\n",
    "df_d.select(list_col).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Mean for filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d.select('ca').agg(f.avg(\"ca\")).collect()[0][0]\n",
    "\n",
    "# df_d = df_d.replace(None,f.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get summary again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace features with names for easier to understand plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df_d\n",
    "\n",
    "df_p = df_p.withColumn('target',f.col('num').cast(\"string\"))\n",
    "df_p = df_p.replace(['1','2','3','4'],\"Disease\", subset='target')\n",
    "df_p = df_p.replace('0',\"No_Disease\", subset='target')\n",
    "\n",
    "df_p = df_p.withColumn('sex',f.col('sex').cast('string'))\n",
    "df_p = df_p.replace({'1.0': \"Male\", '0.0': \"Female\"}, subset='sex')\n",
    "\n",
    "df_p = df_p.withColumn('cp', f.col('cp').cast('string'))\n",
    "df_p = df_p.replace({'2.0': \"atypical_angina\", '1.0': 'typical_angina', '3.0': 'non-anginal pain', '4.0': 'asymptomatic'},\n",
    "            subset='cp')\n",
    "\n",
    "df_p = df_p.withColumn('exang', f.col('exang').cast('string'))\n",
    "df_p = df_p.replace({'0.0': 'True', '1.0': 'False'}, subset = 'exang')\n",
    "\n",
    "df_p = df_p.withColumn('fbs', f.col('fbs').cast('string'))\n",
    "df_p = df_p.replace({'0.0': 'True', '1.0': 'False'}, subset = 'fbs')\n",
    "\n",
    "df_p = df_p.withColumn('slope', f.col('slope').cast('string'))\n",
    "df_p = df_p.replace({'1.0': 'upsloping', '2.0': 'flat', '3.0': 'downsloping'}, subset = 'slope')\n",
    "\n",
    "df_p = df_p.withColumn('thal', f.col('thal').cast('string'))\n",
    "df_p = df_p.replace({'3': 'fixed_defect', '6': 'fixed_defect', '7': \"reversable_defect\"}, subset = 'thal')\n",
    "\n",
    "df_p.show()\n",
    "\n",
    "df_p.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = df_d.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df.plot(kind='box', subplots='True',layout=(2,7),sharex=False,sharey=False, figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.box(pd_df, x='target', y='chol')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = df_p.toPandas()\n",
    "sns.boxplot(x='target',y='chol',data=pd_df,width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the IQR bounds\n",
    "https://blog.zhaytam.com/2019/07/15/outliers-detection-in-pyspark-2-interquartile-range/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## demonstrate Zip an list comprehensions. Curly's used for dictionary, c is first element : second element\n",
    "## in this case the second element is going to be a list of the bounds calculated by approxQuantile.\n",
    "## Use if statements to get only the numerical datatypes\n",
    "{c: d for c,d in zip(df_p.columns,df_p.dtypes) if (d[1] == 'double' or d[1] == 'int') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dictionary Method: create a dictionary of dictionaries for nested addressing later. More complex but better\n",
    "### Var naming\n",
    "dict_bounds = {c: dict(zip(['q1','q3'],df_p.approxQuantile(c,[0.25,.75],0)))\n",
    "          for c,d in zip(df_p.columns,df_p.dtypes) if (d[1] == 'double' or d[1] == 'int') }\n",
    "dict_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in dict_bounds:\n",
    "    iqr = dict_bounds[c]['q3'] - dict_bounds[c]['q1']\n",
    "    dict_bounds[c]['min'] = dict_bounds[c]['q1'] - iqr*1.5\n",
    "    dict_bounds[c]['max'] = dict_bounds[c]['q3'] + iqr*1.5\n",
    "    \n",
    "dict_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply bounds and create new column with outliers flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in dict_bounds:\n",
    "    df_p = df_p.withColumn(c+'_outlier', f.when(\n",
    "        ~f.col(c).between(dict_bounds[c]['min'], dict_bounds[c]['max']), 'True')\n",
    "                .otherwise('False'))\n",
    "\n",
    "df_p.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.select('*').where(f.col('chol_outlier') == True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count and Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{c: df_p.where(f.col(c) == True).count() for c in df_p.columns if c[-7:] == 'outlier'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nout = df_p.select('*').where(\n",
    "    (f.col('age_outlier') == False)\n",
    "    & (f.col(\"trestbps_outlier\") == False)\n",
    "    & (f.col(\"chol_outlier\") == False)\n",
    "    & (f.col(\"restecg_outlier\") == False)\n",
    "    & (f.col(\"thalach_outlier\") == False)\n",
    "    & (f.col(\"oldpeak_outlier\") == False)\n",
    "    & (f.col(\"ca_outlier\") == False)\n",
    "    & (f.col(\"num_outlier\") == False)\n",
    "    )\n",
    "df_nout.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
